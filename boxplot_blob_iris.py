# -*- coding: utf-8 -*-
"""TP 4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ooSF5ruWO4lPlj7hrsMDUcuo3VenvWRn
"""

import matplotlib.pyplot as plt
import numpy as np
# Creating dataset
np.random.seed(10)
data = np.random.normal(100, 20, 200)
fig = plt.figure(figsize =(10, 7))
# Creating plot
plt.boxplot(data)
# show plot
plt.show()

import matplotlib.pyplot as plt
import numpy as np
# Creating dataset
np.random.seed(10)
data_1 = np.random.normal(100, 10, 200)
data_2 = np.random.normal(90, 20, 200)
data_3 = np.random.normal(80, 30, 200)
data_4 = np.random.normal(70, 40, 200)
data = [data_1, data_2, data_3, data_4]
fig = plt.figure(figsize =(10, 7))
# Creating axes instance
ax = fig.add_axes([0, 0, 1, 1])
# Creating plot
bp = ax.boxplot(data)
# show plot
plt.show()

# Import libraries
import matplotlib.pyplot as plt
import numpy as np
# Creating dataset
np.random.seed(10)
data_1 = np.random.normal(100, 10, 200)
data_2 = np.random.normal(90, 20, 200)
data_3 = np.random.normal(80, 30, 200)
data_4 = np.random.normal(70, 40, 200)
data = [data_1, data_2, data_3, data_4]
fig = plt.figure(figsize =(10, 7))
ax = fig.add_subplot(111)
# Creating axes instance
bp = ax.boxplot(data, patch_artist = True,
notch ='True', vert = 0)
colors = ['#0000FF', '#00FF00',
'#FFFF00', '#FF00FF']
for patch, color in zip(bp['boxes'], colors):
  patch.set_facecolor(color)
# changing color and linewidth of
# whiskers
for whisker in bp['whiskers']:
  whisker.set(color ='#8B008B',
    linewidth = 1.5,
    linestyle =":")
# changing color and linewidth of
# caps
for cap in bp['caps']:
  cap.set(color ='#8B008B',
    linewidth = 2)
# changing color and linewidth of
# medians
for median in bp['medians']:
  median.set(color ='red',
    linewidth = 3)
# changing style of fliers
for flier in bp['fliers']:
  flier.set(marker ='D',
    color ='#e7298a',
    alpha = 0.5)
# x-axis labels
ax.set_yticklabels(['data_1', 'data_2',
'data_3', 'data_4'])
# Adding title
plt.title("Customized box plot")
# Removing top axes and right axes
# ticks
ax.get_xaxis().tick_bottom()
ax.get_yaxis().tick_left()
# show plot
plt.show()

"""# **A) et B)**"""

from sklearn import *
import numpy as np
import matplotlib.pyplot as plt

iris = datasets.load_iris()
print(iris)
print(iris.target)
print(iris.feature_names)
print(iris.target_names)
print(iris.target_names[iris.target])
print()
print(iris.data.mean(0))
print(iris.data.std(0))
print(iris.data.min(0))
print(iris.data.max(0))
print()
print(np.size(iris.feature_names))
print(iris.target.size)
print(iris.data.size)

"""# **C)**"""

from pandas.core.algorithms import unique
from sklearn.datasets import fetch_openml
import numpy as np

mln= fetch_openml('mnist_784')

print(mln.data.mean(0))
print(mln.data.std(0))
print(mln.data.min(0))
print(mln.data.max(0))
print()
print(np.size(mln.feature_names))
print(mln.target.size)
print(mln.data.size)
np.unique(mln.data)

"""# **D)**"""

from matplotlib.axes import Subplot
from sklearn.datasets import make_blobs
from sklearn import *
import matplotlib.pyplot as plt

blob=datasets.make_blobs()
X, y = make_blobs(n_samples=1000, centers=4, n_features=2)

from matplotlib.axes import Subplot
from sklearn.datasets import make_blobs
from sklearn import *
import matplotlib.pyplot as plt

blob=datasets.make_blobs()
X, y = make_blobs(n_samples=1000, centers=4, n_features=2)
plt.figure(figsize =(10, 7))
plt.scatter(X[:,0], y)
plt.scatter(X[:,1], y)
plt.title("blobs")
plt.xlim([-15, 15])
plt.ylim([-15, 15])
plt.xlabel("x")
plt.ylabel("y")
plt.show

from matplotlib.axes import Subplot
from sklearn.datasets import make_blobs
from sklearn import *
import matplotlib.pyplot as plt

X, y = make_blobs(n_samples=100, centers=2, n_features=2)
V, w = make_blobs(n_samples=500, centers=3, n_features=2)
X=np.vstack((X, V))
y=np.hstack((y, w))
plt.figure(figsize =(10, 7))
plt.scatter(X[:,0], y)
plt.scatter(X[:,1], y)
plt.show

"""# **E)**"""

from sklearn import *
import numpy as np
import matplotlib.pyplot as plt

iris = datasets.load_iris()
print(iris)
a=np.histogram(iris.data)
plt.hist(a, bins='auto')

from sklearn import *
import numpy as np
import matplotlib.pyplot as plt

iris = datasets.load_iris()
print(iris)
fig = plt.figure(figsize =(10, 7))
fig.add_axes([0, 0, 1, 1])
plt.boxplot(iris.data)
plt.show()

"""Plus un boxplot est dans une petite intervale, plus le bloxplot est bon

# **F)**
"""

def bloxplotblobs():
  fig = plt.figure(figsize =(10, 7))
  fig.add_axes([0, 0, 1, 1])
  plt.boxplot(blobs.data)
  plt.show()
  return

def bloxplotiris():
  fig = plt.figure(figsize =(10, 7))
  fig.add_axes([0, 0, 1, 1])
  plt.boxplot(iris.data)
  plt.show()
  return

def bloxplotdiabete():
  fig = plt.figure(figsize =(10, 7))
  fig.add_axes([0, 0, 1, 1])
  plt.boxplot(diabete.data)
  plt.show()
  return

def histogrammeiris(a):
  a=np.histogram(iris.data)
  plt.hist(a, bins='auto')
  return

def histogrammediabete(a):
  a=np.histogram(diabete.data)
  plt.hist(a, bins='auto')
  return

def histogrammeblobs(a):
  a=np.histogram(blobs.data)
  plt.hist(a, bins='auto')
  return

blobs=datasets.make_blobs()
diabete = datasets.load_diabetes()

a=str(input("Quelle données voulez vous utilisez ?"))

if a == "iris":
  print(iris)
  b=str(input("que souhaitez vous calculez ?"))
  if b == "moyenne":
    print(iris.data.mean(0))
  elif b == "écart-type":
    print(iris.data.std(0))
  elif b == "minimum":
    print(iris.data.min(0))
  elif b == "maximum":
    print(iris.data.max(0))
  elif b == "tout":
    print(iris.data.mean(0))
    print(iris.data.std(0))
    print(iris.data.min(0))
    print(iris.data.max(0))
  else:
    print("erreur, soit moyenne, soit écart-type, soit maximum, soit minimum")
  c = str(input("boxplot ou histogramme ?"))
  if c == "boxplot":
    print(bloxplotdiabete())
  elif c == "histogramme":
      print(histogrammediabete())
elif a== "diabete":
  print(diabete)
  b=str(input("que souhaitez vous calculez ?"))
  if b == "moyenne":
    print(diabete.data.mean(0))
  elif b == "écart-type":
    print(diabete.data.std(0))
  elif b == "minimum":
    print(diabete.data.min(0))
  elif b == "maximum":
    print(diabete.data.max(0))
  elif b == "tout":
    print(diabete.data.mean(0))
    print(diabete.data.std(0))
    print(diabete.data.min(0))
    print(diabete.data.max(0))
  else:
    print("erreur, soit moyenne, soit écart-type, soit maximum, soit minimum")
  c = str(input("boxplot ou histogramme ?"))
  if c == "boxplot":
    print(bloxplotdiabete())
  elif c == "histogramme":
      print(histogrammediabete())
elif a == "blobs":
  données=str(input("combien de données ?"))
  variable=str(input("combien de variable ?"))
  groupe=str(input("combien de groupe ?"))
  X, y = make_blobs(n_samples=données, centers=groupe, n_features=variable)
  b=str(input("que souhaitez vous calculez ?"))
  if b == "moyenne":
    print(blobs.data.mean(0))
  elif b == "écart-type":
    print(blobs.data.std(0))
  elif b == "minimum":
    print(blobs.data.min(0))
  elif b == "maximum":
    print(blobs.data.max(0))
  elif b == "tout":
    print(blobs.data.mean(0))
    print(blobs.data.std(0))
    print(blobs.data.min(0))
    print(blobs.data.max(0))
  c = str(input("boxplot ou histogramme ?"))
  if c == "boxplot":
    print(bloxplotblobs())
  elif c == "histogramme":
    print(histogrammeblobs())

"""# **Partie II**

# **1)**
"""

from sklearn import *
import numpy as np
import matplotlib.pyplot as plt

iris = datasets.load_iris()
print(iris)
print(iris.target)
print(iris.target_names)
print(iris.target_names[iris.target])
print(iris.data.mean(0))
print(iris.data.std(0))
print(iris.data.min(0))
print(iris.data.max(0))
iris.target.size

"""# **2)**"""

plt.scatter(iris.data[:,0],iris.data[:,1],c=iris.target)

plt.scatter(iris.data[:,0],iris.data[:,2],c=iris.target)

plt.scatter(iris.data[:,0],iris.data[:,3],c=iris.target)

plt.scatter(iris.data[:,1],iris.data[:,2],c=iris.target)

plt.scatter(iris.data[:,1],iris.data[:,3],c=iris.target)

plt.scatter(iris.data[:,2],iris.data[:,3],c=iris.target)

"""On voit que le dernier nuage de point est le plus séparé, donc le mieux

# **3)**
"""

CV=iris.data.std(0)/iris.data.mean(0)
print(CV)

"""# **4)**"""

from sklearn.decomposition import PCA
pca=PCA(n_components=2)
pca_iris=pca.fit(iris.data).transform(iris.data)
print(pca)
print(pca_iris)

"""# **5)**"""

np.corrcoef(np.transpose(iris.data))

"""# **Partie A**

# **1) et 2)**
"""

from sklearn import *
import numpy as np
import matplotlib.pyplot as plt

diabete = datasets.load_diabetes()
print(diabete)
plt.boxplot(diabete.data, 0)

"""On remarque que dans le 2ème boxplot (sexe) qu'il est différent car il n'y a que 2 valeurs associés à ce variable (homme et femme).
Plus un boxplot est petit, plus les valeurs sont rapprochés.

# **3)**
"""

plt.scatter(diabete.data[:,2],diabete.data[:,3])

"""# **4)**"""

from sklearn.decomposition import PCA

pca=PCA(n_components=2)
pca_diabete=pca.fit(diabete.data).transform(diabete.data)
print(pca)
print(pca_diabete)
plt.scatter(pca_diabete[:,0],pca_diabete[:,1],c=diabete.target)

"""# **5)**"""

np.corrcoef(np.transpose(diabete.data))

"""# **6)**"""

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = diabete.data
y = diabete.target
x_train, x_test, y_train, y_test = train_test_split( X, y, test_size=20)
model = LinearRegression().fit(x_train, y_train)
print(model.score(x_train, y_train))
model.predict(x_test)

"""# **7)**"""

from sklearn.metrics import mean_squared_error

Xa = diabete.data
ya = diabete.target

model = LinearRegression().fit(Xa, ya)
print(model.score(Xa, ya))
yhat = model.predict(Xa)

print(mean_squared_error(ya,yhat))

"""# **8)**"""

diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

# Use only one feature
diabetes_X = diabetes_X[:, np.newaxis, 2]

# Split the data into training/testing sets
diabetes_X_train = diabetes_X[:-20]
diabetes_X_test = diabetes_X[-20:]

# Split the targets into training/testing sets
diabetes_y_train = diabetes_y[:-20]
diabetes_y_test = diabetes_y[-20:]

# Create linear regression object
regr = linear_model.LinearRegression()

# Train the model using the training sets
regr.fit(diabetes_X_train, diabetes_y_train)

# Make predictions using the testing set
diabetes_y_pred = regr.predict(diabetes_X_test)

plt.scatter(diabetes_X_test, diabetes_y_test, color="black")
plt.plot(diabetes_X_test, diabetes_y_pred, color="blue", linewidth=3)


plt.show()

"""On peut voir sur cette regression lineaire que les points ne sont pas forcément proche de la droite créer mais nous avons tout de même un tendances de tracé.

## Question bonus

# **1)**
"""

reglin=[]
MSE=[]
X = diabete.data
y = diabete.target
for i in range (10):
  x_train, x_test, y_train, y_test = train_test_split(X, y)
  model = LinearRegression().fit(x_train, y_train)
  a= model.score(x_train, y_train)
  print("reg lin:", a)
  reglin.append(a)
  ya = model.predict(X)
  b=mean_squared_error(y,ya)
  MSE.append(b)
  print("MSE:", b)
reglin=np.array(reglin)
print(reglin.mean(0))
print(reglin.std(0))
MSE=np.array(MSE)
print(MSE.mean(0))
print(MSE.std(0))

"""On remarque que les MSE ne sont pas corrélé aux valeurs des coefficients de regression lineaire.

# **2)**
"""

np.corrcoef(np.transpose(diabete.data))